{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "dG7kTgiAq6ch"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import json\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount(\"/content/drive\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KmadvtZfrEVK",
        "outputId": "87e26f4d-bae8-4c6c-9274-04fe2cddebc5"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ROOT_PATH = \"/content/drive/MyDrive/UChicago_MachineLearning/Machine_Learning/Final_Project\""
      ],
      "metadata": {
        "id": "sQDzmC0grES0"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_image_name(img_path):\n",
        "    return img_path.split(\"/\")[-1]"
      ],
      "metadata": {
        "id": "57I4cioJsgyN"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_text_embeddings = pd.read_csv(os.path.join(ROOT_PATH, \"data_preprocessed\", \"train_embedding.csv\"))\n",
        "eval_text_embeddings = pd.read_csv(os.path.join(ROOT_PATH, \"data_preprocessed\", \"eval_embedding.csv\"))\n",
        "test_text_embeddings = pd.read_csv(os.path.join(ROOT_PATH, \"data_preprocessed\", \"test_embedding.csv\"))\n",
        "\n",
        "image_features = pd.read_csv(os.path.join(ROOT_PATH, \"data_preprocessed\", \"image_features.csv\"))"
      ],
      "metadata": {
        "id": "W-fJI0SCrEQ8"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_text_embeddings[\"img_name\"] = train_text_embeddings[\"img\"].apply(lambda t: get_image_name(t))\n",
        "eval_text_embeddings[\"img_name\"] = eval_text_embeddings[\"img\"].apply(lambda t: get_image_name(t))\n",
        "test_text_embeddings[\"img_name\"] = test_text_embeddings[\"img\"].apply(lambda t: get_image_name(t))\n",
        "\n",
        "text_embeddings = pd.concat([train_text_embeddings, eval_text_embeddings, test_text_embeddings])\n",
        "text_embeddings"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "nIme1W1QsogS",
        "outputId": "7e10af8c-67e6-4ea2-8984-b68f763bd41f"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        id            img  label  \\\n",
              "0    42953  img/42953.png    0.0   \n",
              "1    23058  img/23058.png    0.0   \n",
              "2    13894  img/13894.png    0.0   \n",
              "3    37408  img/37408.png    0.0   \n",
              "4    82403  img/82403.png    0.0   \n",
              "..     ...            ...    ...   \n",
              "995   3869  img/03869.png    NaN   \n",
              "996  23817  img/23817.png    NaN   \n",
              "997  56280  img/56280.png    NaN   \n",
              "998  29384  img/29384.png    NaN   \n",
              "999  34127  img/34127.png    NaN   \n",
              "\n",
              "                                                  text  embedding_0  \\\n",
              "0     its their character not their color that matters    -0.047270   \n",
              "1    don't be afraid to love again everyone is not ...    -0.044260   \n",
              "2                             putting bows on your pet    -0.052200   \n",
              "3    i love everything and everybody! except for sq...    -0.045982   \n",
              "4    everybody loves chocolate chip cookies, even h...    -0.045905   \n",
              "..                                                 ...          ...   \n",
              "995    a mother's love for the child is a divine thing    -0.043596   \n",
              "996                                        sea monkeys    -0.063568   \n",
              "997               little miss muffet sat on her tuffet    -0.057040   \n",
              "998                                   they're in a row    -0.048560   \n",
              "999  that feeling when you win a fifa game after be...    -0.039256   \n",
              "\n",
              "     embedding_1  embedding_2  embedding_3  embedding_4  embedding_5  ...  \\\n",
              "0       0.081864     0.032437    -0.151744     0.049869     0.274994  ...   \n",
              "1       0.081599     0.024389    -0.146163     0.046460     0.255240  ...   \n",
              "2       0.073329     0.021844    -0.134351     0.040769     0.272686  ...   \n",
              "3       0.080845     0.045772    -0.142562     0.057844     0.263742  ...   \n",
              "4       0.074049     0.047349    -0.165169     0.053242     0.253701  ...   \n",
              "..           ...          ...          ...          ...          ...  ...   \n",
              "995     0.071649     0.021350    -0.144111     0.047820     0.262714  ...   \n",
              "996     0.090432     0.027261    -0.141797     0.074833     0.261448  ...   \n",
              "997     0.077044     0.019531    -0.140951     0.043943     0.257759  ...   \n",
              "998     0.079420     0.025237    -0.128166     0.062118     0.258481  ...   \n",
              "999     0.071438     0.030978    -0.136096     0.049952     0.270463  ...   \n",
              "\n",
              "     embedding_91  embedding_92  embedding_93  embedding_94  embedding_95  \\\n",
              "0       -0.003773      0.056420      0.018093     -0.000858     -0.126719   \n",
              "1        0.003364      0.052712      0.018431      0.001211     -0.129407   \n",
              "2       -0.020424      0.046338      0.003759     -0.008393     -0.137328   \n",
              "3        0.001266      0.029108      0.038134      0.001083     -0.127383   \n",
              "4        0.025660      0.017383      0.065593      0.040692     -0.127206   \n",
              "..            ...           ...           ...           ...           ...   \n",
              "995     -0.005000      0.072216     -0.000174     -0.002168     -0.125655   \n",
              "996      0.021409      0.031796      0.037884     -0.013264     -0.130613   \n",
              "997      0.008929      0.039901      0.014965     -0.005057     -0.135704   \n",
              "998     -0.004602      0.040357      0.012497     -0.029748     -0.125328   \n",
              "999     -0.026367      0.065516     -0.003052     -0.015010     -0.130595   \n",
              "\n",
              "     embedding_96  embedding_97  embedding_98  embedding_99   img_name  \n",
              "0        0.038306      0.173042     -0.080767     -0.104416  42953.png  \n",
              "1        0.036726      0.171141     -0.089248     -0.101055  23058.png  \n",
              "2        0.047681      0.180136     -0.073047     -0.107347  13894.png  \n",
              "3        0.049963      0.161953     -0.076331     -0.104860  37408.png  \n",
              "4        0.060397      0.129530     -0.067772     -0.088842  82403.png  \n",
              "..            ...           ...           ...           ...        ...  \n",
              "995      0.027597      0.177722     -0.079459     -0.097614  03869.png  \n",
              "996      0.050331      0.176603     -0.087333     -0.099329  23817.png  \n",
              "997      0.042235      0.178850     -0.089424     -0.107502  56280.png  \n",
              "998      0.035054      0.185169     -0.076505     -0.103528  29384.png  \n",
              "999      0.034764      0.186989     -0.068697     -0.106761  34127.png  \n",
              "\n",
              "[10000 rows x 105 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8b3936db-6f01-4f85-99c3-d56a2cfee36d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>img</th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "      <th>embedding_0</th>\n",
              "      <th>embedding_1</th>\n",
              "      <th>embedding_2</th>\n",
              "      <th>embedding_3</th>\n",
              "      <th>embedding_4</th>\n",
              "      <th>embedding_5</th>\n",
              "      <th>...</th>\n",
              "      <th>embedding_91</th>\n",
              "      <th>embedding_92</th>\n",
              "      <th>embedding_93</th>\n",
              "      <th>embedding_94</th>\n",
              "      <th>embedding_95</th>\n",
              "      <th>embedding_96</th>\n",
              "      <th>embedding_97</th>\n",
              "      <th>embedding_98</th>\n",
              "      <th>embedding_99</th>\n",
              "      <th>img_name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>42953</td>\n",
              "      <td>img/42953.png</td>\n",
              "      <td>0.0</td>\n",
              "      <td>its their character not their color that matters</td>\n",
              "      <td>-0.047270</td>\n",
              "      <td>0.081864</td>\n",
              "      <td>0.032437</td>\n",
              "      <td>-0.151744</td>\n",
              "      <td>0.049869</td>\n",
              "      <td>0.274994</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.003773</td>\n",
              "      <td>0.056420</td>\n",
              "      <td>0.018093</td>\n",
              "      <td>-0.000858</td>\n",
              "      <td>-0.126719</td>\n",
              "      <td>0.038306</td>\n",
              "      <td>0.173042</td>\n",
              "      <td>-0.080767</td>\n",
              "      <td>-0.104416</td>\n",
              "      <td>42953.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>23058</td>\n",
              "      <td>img/23058.png</td>\n",
              "      <td>0.0</td>\n",
              "      <td>don't be afraid to love again everyone is not ...</td>\n",
              "      <td>-0.044260</td>\n",
              "      <td>0.081599</td>\n",
              "      <td>0.024389</td>\n",
              "      <td>-0.146163</td>\n",
              "      <td>0.046460</td>\n",
              "      <td>0.255240</td>\n",
              "      <td>...</td>\n",
              "      <td>0.003364</td>\n",
              "      <td>0.052712</td>\n",
              "      <td>0.018431</td>\n",
              "      <td>0.001211</td>\n",
              "      <td>-0.129407</td>\n",
              "      <td>0.036726</td>\n",
              "      <td>0.171141</td>\n",
              "      <td>-0.089248</td>\n",
              "      <td>-0.101055</td>\n",
              "      <td>23058.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>13894</td>\n",
              "      <td>img/13894.png</td>\n",
              "      <td>0.0</td>\n",
              "      <td>putting bows on your pet</td>\n",
              "      <td>-0.052200</td>\n",
              "      <td>0.073329</td>\n",
              "      <td>0.021844</td>\n",
              "      <td>-0.134351</td>\n",
              "      <td>0.040769</td>\n",
              "      <td>0.272686</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.020424</td>\n",
              "      <td>0.046338</td>\n",
              "      <td>0.003759</td>\n",
              "      <td>-0.008393</td>\n",
              "      <td>-0.137328</td>\n",
              "      <td>0.047681</td>\n",
              "      <td>0.180136</td>\n",
              "      <td>-0.073047</td>\n",
              "      <td>-0.107347</td>\n",
              "      <td>13894.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>37408</td>\n",
              "      <td>img/37408.png</td>\n",
              "      <td>0.0</td>\n",
              "      <td>i love everything and everybody! except for sq...</td>\n",
              "      <td>-0.045982</td>\n",
              "      <td>0.080845</td>\n",
              "      <td>0.045772</td>\n",
              "      <td>-0.142562</td>\n",
              "      <td>0.057844</td>\n",
              "      <td>0.263742</td>\n",
              "      <td>...</td>\n",
              "      <td>0.001266</td>\n",
              "      <td>0.029108</td>\n",
              "      <td>0.038134</td>\n",
              "      <td>0.001083</td>\n",
              "      <td>-0.127383</td>\n",
              "      <td>0.049963</td>\n",
              "      <td>0.161953</td>\n",
              "      <td>-0.076331</td>\n",
              "      <td>-0.104860</td>\n",
              "      <td>37408.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>82403</td>\n",
              "      <td>img/82403.png</td>\n",
              "      <td>0.0</td>\n",
              "      <td>everybody loves chocolate chip cookies, even h...</td>\n",
              "      <td>-0.045905</td>\n",
              "      <td>0.074049</td>\n",
              "      <td>0.047349</td>\n",
              "      <td>-0.165169</td>\n",
              "      <td>0.053242</td>\n",
              "      <td>0.253701</td>\n",
              "      <td>...</td>\n",
              "      <td>0.025660</td>\n",
              "      <td>0.017383</td>\n",
              "      <td>0.065593</td>\n",
              "      <td>0.040692</td>\n",
              "      <td>-0.127206</td>\n",
              "      <td>0.060397</td>\n",
              "      <td>0.129530</td>\n",
              "      <td>-0.067772</td>\n",
              "      <td>-0.088842</td>\n",
              "      <td>82403.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>995</th>\n",
              "      <td>3869</td>\n",
              "      <td>img/03869.png</td>\n",
              "      <td>NaN</td>\n",
              "      <td>a mother's love for the child is a divine thing</td>\n",
              "      <td>-0.043596</td>\n",
              "      <td>0.071649</td>\n",
              "      <td>0.021350</td>\n",
              "      <td>-0.144111</td>\n",
              "      <td>0.047820</td>\n",
              "      <td>0.262714</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.005000</td>\n",
              "      <td>0.072216</td>\n",
              "      <td>-0.000174</td>\n",
              "      <td>-0.002168</td>\n",
              "      <td>-0.125655</td>\n",
              "      <td>0.027597</td>\n",
              "      <td>0.177722</td>\n",
              "      <td>-0.079459</td>\n",
              "      <td>-0.097614</td>\n",
              "      <td>03869.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>996</th>\n",
              "      <td>23817</td>\n",
              "      <td>img/23817.png</td>\n",
              "      <td>NaN</td>\n",
              "      <td>sea monkeys</td>\n",
              "      <td>-0.063568</td>\n",
              "      <td>0.090432</td>\n",
              "      <td>0.027261</td>\n",
              "      <td>-0.141797</td>\n",
              "      <td>0.074833</td>\n",
              "      <td>0.261448</td>\n",
              "      <td>...</td>\n",
              "      <td>0.021409</td>\n",
              "      <td>0.031796</td>\n",
              "      <td>0.037884</td>\n",
              "      <td>-0.013264</td>\n",
              "      <td>-0.130613</td>\n",
              "      <td>0.050331</td>\n",
              "      <td>0.176603</td>\n",
              "      <td>-0.087333</td>\n",
              "      <td>-0.099329</td>\n",
              "      <td>23817.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>997</th>\n",
              "      <td>56280</td>\n",
              "      <td>img/56280.png</td>\n",
              "      <td>NaN</td>\n",
              "      <td>little miss muffet sat on her tuffet</td>\n",
              "      <td>-0.057040</td>\n",
              "      <td>0.077044</td>\n",
              "      <td>0.019531</td>\n",
              "      <td>-0.140951</td>\n",
              "      <td>0.043943</td>\n",
              "      <td>0.257759</td>\n",
              "      <td>...</td>\n",
              "      <td>0.008929</td>\n",
              "      <td>0.039901</td>\n",
              "      <td>0.014965</td>\n",
              "      <td>-0.005057</td>\n",
              "      <td>-0.135704</td>\n",
              "      <td>0.042235</td>\n",
              "      <td>0.178850</td>\n",
              "      <td>-0.089424</td>\n",
              "      <td>-0.107502</td>\n",
              "      <td>56280.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>998</th>\n",
              "      <td>29384</td>\n",
              "      <td>img/29384.png</td>\n",
              "      <td>NaN</td>\n",
              "      <td>they're in a row</td>\n",
              "      <td>-0.048560</td>\n",
              "      <td>0.079420</td>\n",
              "      <td>0.025237</td>\n",
              "      <td>-0.128166</td>\n",
              "      <td>0.062118</td>\n",
              "      <td>0.258481</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.004602</td>\n",
              "      <td>0.040357</td>\n",
              "      <td>0.012497</td>\n",
              "      <td>-0.029748</td>\n",
              "      <td>-0.125328</td>\n",
              "      <td>0.035054</td>\n",
              "      <td>0.185169</td>\n",
              "      <td>-0.076505</td>\n",
              "      <td>-0.103528</td>\n",
              "      <td>29384.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>999</th>\n",
              "      <td>34127</td>\n",
              "      <td>img/34127.png</td>\n",
              "      <td>NaN</td>\n",
              "      <td>that feeling when you win a fifa game after be...</td>\n",
              "      <td>-0.039256</td>\n",
              "      <td>0.071438</td>\n",
              "      <td>0.030978</td>\n",
              "      <td>-0.136096</td>\n",
              "      <td>0.049952</td>\n",
              "      <td>0.270463</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.026367</td>\n",
              "      <td>0.065516</td>\n",
              "      <td>-0.003052</td>\n",
              "      <td>-0.015010</td>\n",
              "      <td>-0.130595</td>\n",
              "      <td>0.034764</td>\n",
              "      <td>0.186989</td>\n",
              "      <td>-0.068697</td>\n",
              "      <td>-0.106761</td>\n",
              "      <td>34127.png</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10000 rows × 105 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8b3936db-6f01-4f85-99c3-d56a2cfee36d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8b3936db-6f01-4f85-99c3-d56a2cfee36d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8b3936db-6f01-4f85-99c3-d56a2cfee36d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_features.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 629
        },
        "id": "p_ajWvRJrEOv",
        "outputId": "81391d91-1ec1-40a8-b1ad-c3d83edf93c9"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        path  feature_0  feature_1  feature_2  feature_3  feature_4  \\\n",
              "0  01456.png   0.530085   0.488977  -0.113115   0.015020  -0.027616   \n",
              "1  01726.png   0.303321  -0.136549  -0.679844   0.259443  -0.509942   \n",
              "2  01765.png  -0.067749  -0.180159  -1.306831   0.213957   0.266355   \n",
              "3  01796.png   0.665094   0.182436  -0.287966  -0.169398   0.269944   \n",
              "4  01925.png   0.018574   0.498051  -0.479313  -0.028792  -0.145709   \n",
              "\n",
              "   feature_5  feature_6  feature_7  feature_8  ...  feature_14  feature_15  \\\n",
              "0  -0.427606  -0.750996   0.011548   0.858244  ...   -0.384014    0.025911   \n",
              "1  -0.401917  -0.264162   0.396859  -0.031298  ...   -1.285323    0.260769   \n",
              "2   0.181536   0.292081  -0.296363   0.891020  ...   -0.592484   -0.284378   \n",
              "3   0.081864  -0.097685   0.088677   0.409557  ...   -1.197587   -0.107875   \n",
              "4   0.267059   0.150578  -0.161765   0.767828  ...   -0.308409    0.656898   \n",
              "\n",
              "   feature_16  feature_17  feature_18  feature_19  label    id  dataset  \\\n",
              "0    0.547540    0.153631    0.266383    0.455937      0  1456     eval   \n",
              "1    1.072918    0.387688   -0.013143   -0.210215      0  1726     eval   \n",
              "2    0.074950    0.531769    0.275458    0.189499      0  1765     eval   \n",
              "3    0.489352    0.032808    0.393425    0.385427      0  1796     eval   \n",
              "4    1.045326    0.049474   -0.052531   -0.018084      0  1925     eval   \n",
              "\n",
              "                                                text  \n",
              "0            they see them rollin..... they hating..  \n",
              "1        a real man loads the dishwasher every night  \n",
              "2  after a girl dies, what organ in her body stay...  \n",
              "3       life hack #23 how to get stoned with no weed  \n",
              "4      i am not racist i just don't like brown sugar  \n",
              "\n",
              "[5 rows x 25 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-de37c492-b077-4c47-bf9f-8e30027f84f0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>path</th>\n",
              "      <th>feature_0</th>\n",
              "      <th>feature_1</th>\n",
              "      <th>feature_2</th>\n",
              "      <th>feature_3</th>\n",
              "      <th>feature_4</th>\n",
              "      <th>feature_5</th>\n",
              "      <th>feature_6</th>\n",
              "      <th>feature_7</th>\n",
              "      <th>feature_8</th>\n",
              "      <th>...</th>\n",
              "      <th>feature_14</th>\n",
              "      <th>feature_15</th>\n",
              "      <th>feature_16</th>\n",
              "      <th>feature_17</th>\n",
              "      <th>feature_18</th>\n",
              "      <th>feature_19</th>\n",
              "      <th>label</th>\n",
              "      <th>id</th>\n",
              "      <th>dataset</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>01456.png</td>\n",
              "      <td>0.530085</td>\n",
              "      <td>0.488977</td>\n",
              "      <td>-0.113115</td>\n",
              "      <td>0.015020</td>\n",
              "      <td>-0.027616</td>\n",
              "      <td>-0.427606</td>\n",
              "      <td>-0.750996</td>\n",
              "      <td>0.011548</td>\n",
              "      <td>0.858244</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.384014</td>\n",
              "      <td>0.025911</td>\n",
              "      <td>0.547540</td>\n",
              "      <td>0.153631</td>\n",
              "      <td>0.266383</td>\n",
              "      <td>0.455937</td>\n",
              "      <td>0</td>\n",
              "      <td>1456</td>\n",
              "      <td>eval</td>\n",
              "      <td>they see them rollin..... they hating..</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>01726.png</td>\n",
              "      <td>0.303321</td>\n",
              "      <td>-0.136549</td>\n",
              "      <td>-0.679844</td>\n",
              "      <td>0.259443</td>\n",
              "      <td>-0.509942</td>\n",
              "      <td>-0.401917</td>\n",
              "      <td>-0.264162</td>\n",
              "      <td>0.396859</td>\n",
              "      <td>-0.031298</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.285323</td>\n",
              "      <td>0.260769</td>\n",
              "      <td>1.072918</td>\n",
              "      <td>0.387688</td>\n",
              "      <td>-0.013143</td>\n",
              "      <td>-0.210215</td>\n",
              "      <td>0</td>\n",
              "      <td>1726</td>\n",
              "      <td>eval</td>\n",
              "      <td>a real man loads the dishwasher every night</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>01765.png</td>\n",
              "      <td>-0.067749</td>\n",
              "      <td>-0.180159</td>\n",
              "      <td>-1.306831</td>\n",
              "      <td>0.213957</td>\n",
              "      <td>0.266355</td>\n",
              "      <td>0.181536</td>\n",
              "      <td>0.292081</td>\n",
              "      <td>-0.296363</td>\n",
              "      <td>0.891020</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.592484</td>\n",
              "      <td>-0.284378</td>\n",
              "      <td>0.074950</td>\n",
              "      <td>0.531769</td>\n",
              "      <td>0.275458</td>\n",
              "      <td>0.189499</td>\n",
              "      <td>0</td>\n",
              "      <td>1765</td>\n",
              "      <td>eval</td>\n",
              "      <td>after a girl dies, what organ in her body stay...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>01796.png</td>\n",
              "      <td>0.665094</td>\n",
              "      <td>0.182436</td>\n",
              "      <td>-0.287966</td>\n",
              "      <td>-0.169398</td>\n",
              "      <td>0.269944</td>\n",
              "      <td>0.081864</td>\n",
              "      <td>-0.097685</td>\n",
              "      <td>0.088677</td>\n",
              "      <td>0.409557</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.197587</td>\n",
              "      <td>-0.107875</td>\n",
              "      <td>0.489352</td>\n",
              "      <td>0.032808</td>\n",
              "      <td>0.393425</td>\n",
              "      <td>0.385427</td>\n",
              "      <td>0</td>\n",
              "      <td>1796</td>\n",
              "      <td>eval</td>\n",
              "      <td>life hack #23 how to get stoned with no weed</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>01925.png</td>\n",
              "      <td>0.018574</td>\n",
              "      <td>0.498051</td>\n",
              "      <td>-0.479313</td>\n",
              "      <td>-0.028792</td>\n",
              "      <td>-0.145709</td>\n",
              "      <td>0.267059</td>\n",
              "      <td>0.150578</td>\n",
              "      <td>-0.161765</td>\n",
              "      <td>0.767828</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.308409</td>\n",
              "      <td>0.656898</td>\n",
              "      <td>1.045326</td>\n",
              "      <td>0.049474</td>\n",
              "      <td>-0.052531</td>\n",
              "      <td>-0.018084</td>\n",
              "      <td>0</td>\n",
              "      <td>1925</td>\n",
              "      <td>eval</td>\n",
              "      <td>i am not racist i just don't like brown sugar</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 25 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-de37c492-b077-4c47-bf9f-8e30027f84f0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-de37c492-b077-4c47-bf9f-8e30027f84f0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-de37c492-b077-4c47-bf9f-8e30027f84f0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = image_features.set_index(\"id\").join(text_embeddings.set_index(\"id\"), how=\"left\", rsuffix=\"_text\")"
      ],
      "metadata": {
        "id": "bguPiLJ_rEMt"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 519
        },
        "id": "BiNj-LvDrEKW",
        "outputId": "d40b3332-dde8-460f-923c-506088405d43"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            path  feature_0  feature_1  feature_2  feature_3  feature_4  \\\n",
              "id                                                                        \n",
              "1456   01456.png   0.530085   0.488977  -0.113115   0.015020  -0.027616   \n",
              "1726   01726.png   0.303321  -0.136549  -0.679844   0.259443  -0.509942   \n",
              "1765   01765.png  -0.067749  -0.180159  -1.306831   0.213957   0.266355   \n",
              "1796   01796.png   0.665094   0.182436  -0.287966  -0.169398   0.269944   \n",
              "1925   01925.png   0.018574   0.498051  -0.479313  -0.028792  -0.145709   \n",
              "...          ...        ...        ...        ...        ...        ...   \n",
              "98731  98731.png   0.629275   0.780988  -0.913025  -0.334055  -0.743344   \n",
              "98751  98751.png   0.476889   0.117571  -0.436004  -0.223811  -0.653168   \n",
              "98752  98752.png   0.612847   0.098404   0.271644   0.129210   1.128640   \n",
              "98762  98762.png   0.537348   0.045794  -0.351427  -0.309101   0.298712   \n",
              "98764  98764.png   0.354626  -0.748701  -0.044807   0.309230  -0.702635   \n",
              "\n",
              "       feature_5  feature_6  feature_7  feature_8  ...  embedding_91  \\\n",
              "id                                                 ...                 \n",
              "1456   -0.427606  -0.750996   0.011548   0.858244  ...     -0.026445   \n",
              "1726   -0.401917  -0.264162   0.396859  -0.031298  ...      0.004484   \n",
              "1765    0.181536   0.292081  -0.296363   0.891020  ...      0.004229   \n",
              "1796    0.081864  -0.097685   0.088677   0.409557  ...      0.003539   \n",
              "1925    0.267059   0.150578  -0.161765   0.767828  ...     -0.012824   \n",
              "...          ...        ...        ...        ...  ...           ...   \n",
              "98731   0.061763   0.039855   0.137024   0.910905  ...     -0.008238   \n",
              "98751  -0.422667   0.283257  -0.072312   0.698379  ...     -0.008634   \n",
              "98752  -0.890068   0.062885   0.398054   0.309193  ...      0.008474   \n",
              "98762   0.010709  -0.658435   0.294491   0.482246  ...      0.014730   \n",
              "98764   0.014397   0.345474  -0.543051   1.603948  ...     -0.021634   \n",
              "\n",
              "       embedding_92  embedding_93  embedding_94  embedding_95  embedding_96  \\\n",
              "id                                                                            \n",
              "1456       0.074812     -0.004319     -0.019604     -0.116870      0.034551   \n",
              "1726       0.050338      0.020772      0.006284     -0.125223      0.041814   \n",
              "1765       0.042607      0.018578     -0.009406     -0.127428      0.036498   \n",
              "1796       0.045787      0.027744      0.000234     -0.130943      0.045098   \n",
              "1925       0.053689      0.009628     -0.010846     -0.129269      0.037502   \n",
              "...             ...           ...           ...           ...           ...   \n",
              "98731      0.053880      0.012093     -0.007553     -0.127643      0.041135   \n",
              "98751      0.048622      0.004992     -0.021623     -0.130193      0.039295   \n",
              "98752      0.045627      0.019521     -0.003757     -0.132730      0.045302   \n",
              "98762      0.030162      0.042448      0.000556     -0.132988      0.045271   \n",
              "98764      0.049249      0.012138     -0.016587     -0.137476      0.051217   \n",
              "\n",
              "       embedding_97  embedding_98  embedding_99   img_name  \n",
              "id                                                          \n",
              "1456       0.183631     -0.071114     -0.111196  01456.png  \n",
              "1726       0.167857     -0.075193     -0.099655  01726.png  \n",
              "1765       0.173000     -0.077927     -0.101257  01765.png  \n",
              "1796       0.172570     -0.081977     -0.102081  01796.png  \n",
              "1925       0.187188     -0.092233     -0.113070  01925.png  \n",
              "...             ...           ...           ...        ...  \n",
              "98731      0.183989     -0.082890     -0.114056  98731.png  \n",
              "98751      0.187193     -0.085848     -0.112628  98751.png  \n",
              "98752      0.182609     -0.086659     -0.113970  98752.png  \n",
              "98762      0.163318     -0.078031     -0.092863  98762.png  \n",
              "98764      0.178226     -0.065143     -0.101045  98764.png  \n",
              "\n",
              "[8986 rows x 128 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-22fedf28-ee3e-4b2f-bae1-faa01ab3190c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>path</th>\n",
              "      <th>feature_0</th>\n",
              "      <th>feature_1</th>\n",
              "      <th>feature_2</th>\n",
              "      <th>feature_3</th>\n",
              "      <th>feature_4</th>\n",
              "      <th>feature_5</th>\n",
              "      <th>feature_6</th>\n",
              "      <th>feature_7</th>\n",
              "      <th>feature_8</th>\n",
              "      <th>...</th>\n",
              "      <th>embedding_91</th>\n",
              "      <th>embedding_92</th>\n",
              "      <th>embedding_93</th>\n",
              "      <th>embedding_94</th>\n",
              "      <th>embedding_95</th>\n",
              "      <th>embedding_96</th>\n",
              "      <th>embedding_97</th>\n",
              "      <th>embedding_98</th>\n",
              "      <th>embedding_99</th>\n",
              "      <th>img_name</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1456</th>\n",
              "      <td>01456.png</td>\n",
              "      <td>0.530085</td>\n",
              "      <td>0.488977</td>\n",
              "      <td>-0.113115</td>\n",
              "      <td>0.015020</td>\n",
              "      <td>-0.027616</td>\n",
              "      <td>-0.427606</td>\n",
              "      <td>-0.750996</td>\n",
              "      <td>0.011548</td>\n",
              "      <td>0.858244</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.026445</td>\n",
              "      <td>0.074812</td>\n",
              "      <td>-0.004319</td>\n",
              "      <td>-0.019604</td>\n",
              "      <td>-0.116870</td>\n",
              "      <td>0.034551</td>\n",
              "      <td>0.183631</td>\n",
              "      <td>-0.071114</td>\n",
              "      <td>-0.111196</td>\n",
              "      <td>01456.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1726</th>\n",
              "      <td>01726.png</td>\n",
              "      <td>0.303321</td>\n",
              "      <td>-0.136549</td>\n",
              "      <td>-0.679844</td>\n",
              "      <td>0.259443</td>\n",
              "      <td>-0.509942</td>\n",
              "      <td>-0.401917</td>\n",
              "      <td>-0.264162</td>\n",
              "      <td>0.396859</td>\n",
              "      <td>-0.031298</td>\n",
              "      <td>...</td>\n",
              "      <td>0.004484</td>\n",
              "      <td>0.050338</td>\n",
              "      <td>0.020772</td>\n",
              "      <td>0.006284</td>\n",
              "      <td>-0.125223</td>\n",
              "      <td>0.041814</td>\n",
              "      <td>0.167857</td>\n",
              "      <td>-0.075193</td>\n",
              "      <td>-0.099655</td>\n",
              "      <td>01726.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1765</th>\n",
              "      <td>01765.png</td>\n",
              "      <td>-0.067749</td>\n",
              "      <td>-0.180159</td>\n",
              "      <td>-1.306831</td>\n",
              "      <td>0.213957</td>\n",
              "      <td>0.266355</td>\n",
              "      <td>0.181536</td>\n",
              "      <td>0.292081</td>\n",
              "      <td>-0.296363</td>\n",
              "      <td>0.891020</td>\n",
              "      <td>...</td>\n",
              "      <td>0.004229</td>\n",
              "      <td>0.042607</td>\n",
              "      <td>0.018578</td>\n",
              "      <td>-0.009406</td>\n",
              "      <td>-0.127428</td>\n",
              "      <td>0.036498</td>\n",
              "      <td>0.173000</td>\n",
              "      <td>-0.077927</td>\n",
              "      <td>-0.101257</td>\n",
              "      <td>01765.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1796</th>\n",
              "      <td>01796.png</td>\n",
              "      <td>0.665094</td>\n",
              "      <td>0.182436</td>\n",
              "      <td>-0.287966</td>\n",
              "      <td>-0.169398</td>\n",
              "      <td>0.269944</td>\n",
              "      <td>0.081864</td>\n",
              "      <td>-0.097685</td>\n",
              "      <td>0.088677</td>\n",
              "      <td>0.409557</td>\n",
              "      <td>...</td>\n",
              "      <td>0.003539</td>\n",
              "      <td>0.045787</td>\n",
              "      <td>0.027744</td>\n",
              "      <td>0.000234</td>\n",
              "      <td>-0.130943</td>\n",
              "      <td>0.045098</td>\n",
              "      <td>0.172570</td>\n",
              "      <td>-0.081977</td>\n",
              "      <td>-0.102081</td>\n",
              "      <td>01796.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1925</th>\n",
              "      <td>01925.png</td>\n",
              "      <td>0.018574</td>\n",
              "      <td>0.498051</td>\n",
              "      <td>-0.479313</td>\n",
              "      <td>-0.028792</td>\n",
              "      <td>-0.145709</td>\n",
              "      <td>0.267059</td>\n",
              "      <td>0.150578</td>\n",
              "      <td>-0.161765</td>\n",
              "      <td>0.767828</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.012824</td>\n",
              "      <td>0.053689</td>\n",
              "      <td>0.009628</td>\n",
              "      <td>-0.010846</td>\n",
              "      <td>-0.129269</td>\n",
              "      <td>0.037502</td>\n",
              "      <td>0.187188</td>\n",
              "      <td>-0.092233</td>\n",
              "      <td>-0.113070</td>\n",
              "      <td>01925.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98731</th>\n",
              "      <td>98731.png</td>\n",
              "      <td>0.629275</td>\n",
              "      <td>0.780988</td>\n",
              "      <td>-0.913025</td>\n",
              "      <td>-0.334055</td>\n",
              "      <td>-0.743344</td>\n",
              "      <td>0.061763</td>\n",
              "      <td>0.039855</td>\n",
              "      <td>0.137024</td>\n",
              "      <td>0.910905</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.008238</td>\n",
              "      <td>0.053880</td>\n",
              "      <td>0.012093</td>\n",
              "      <td>-0.007553</td>\n",
              "      <td>-0.127643</td>\n",
              "      <td>0.041135</td>\n",
              "      <td>0.183989</td>\n",
              "      <td>-0.082890</td>\n",
              "      <td>-0.114056</td>\n",
              "      <td>98731.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98751</th>\n",
              "      <td>98751.png</td>\n",
              "      <td>0.476889</td>\n",
              "      <td>0.117571</td>\n",
              "      <td>-0.436004</td>\n",
              "      <td>-0.223811</td>\n",
              "      <td>-0.653168</td>\n",
              "      <td>-0.422667</td>\n",
              "      <td>0.283257</td>\n",
              "      <td>-0.072312</td>\n",
              "      <td>0.698379</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.008634</td>\n",
              "      <td>0.048622</td>\n",
              "      <td>0.004992</td>\n",
              "      <td>-0.021623</td>\n",
              "      <td>-0.130193</td>\n",
              "      <td>0.039295</td>\n",
              "      <td>0.187193</td>\n",
              "      <td>-0.085848</td>\n",
              "      <td>-0.112628</td>\n",
              "      <td>98751.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98752</th>\n",
              "      <td>98752.png</td>\n",
              "      <td>0.612847</td>\n",
              "      <td>0.098404</td>\n",
              "      <td>0.271644</td>\n",
              "      <td>0.129210</td>\n",
              "      <td>1.128640</td>\n",
              "      <td>-0.890068</td>\n",
              "      <td>0.062885</td>\n",
              "      <td>0.398054</td>\n",
              "      <td>0.309193</td>\n",
              "      <td>...</td>\n",
              "      <td>0.008474</td>\n",
              "      <td>0.045627</td>\n",
              "      <td>0.019521</td>\n",
              "      <td>-0.003757</td>\n",
              "      <td>-0.132730</td>\n",
              "      <td>0.045302</td>\n",
              "      <td>0.182609</td>\n",
              "      <td>-0.086659</td>\n",
              "      <td>-0.113970</td>\n",
              "      <td>98752.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98762</th>\n",
              "      <td>98762.png</td>\n",
              "      <td>0.537348</td>\n",
              "      <td>0.045794</td>\n",
              "      <td>-0.351427</td>\n",
              "      <td>-0.309101</td>\n",
              "      <td>0.298712</td>\n",
              "      <td>0.010709</td>\n",
              "      <td>-0.658435</td>\n",
              "      <td>0.294491</td>\n",
              "      <td>0.482246</td>\n",
              "      <td>...</td>\n",
              "      <td>0.014730</td>\n",
              "      <td>0.030162</td>\n",
              "      <td>0.042448</td>\n",
              "      <td>0.000556</td>\n",
              "      <td>-0.132988</td>\n",
              "      <td>0.045271</td>\n",
              "      <td>0.163318</td>\n",
              "      <td>-0.078031</td>\n",
              "      <td>-0.092863</td>\n",
              "      <td>98762.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98764</th>\n",
              "      <td>98764.png</td>\n",
              "      <td>0.354626</td>\n",
              "      <td>-0.748701</td>\n",
              "      <td>-0.044807</td>\n",
              "      <td>0.309230</td>\n",
              "      <td>-0.702635</td>\n",
              "      <td>0.014397</td>\n",
              "      <td>0.345474</td>\n",
              "      <td>-0.543051</td>\n",
              "      <td>1.603948</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.021634</td>\n",
              "      <td>0.049249</td>\n",
              "      <td>0.012138</td>\n",
              "      <td>-0.016587</td>\n",
              "      <td>-0.137476</td>\n",
              "      <td>0.051217</td>\n",
              "      <td>0.178226</td>\n",
              "      <td>-0.065143</td>\n",
              "      <td>-0.101045</td>\n",
              "      <td>98764.png</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8986 rows × 128 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-22fedf28-ee3e-4b2f-bae1-faa01ab3190c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-22fedf28-ee3e-4b2f-bae1-faa01ab3190c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-22fedf28-ee3e-4b2f-bae1-faa01ab3190c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_text_columns(dataframe):\n",
        "    columns_to_remove = [col for col in dataframe.columns if col.endswith('_text')]\n",
        "    dataframe = dataframe.drop(columns=columns_to_remove)\n",
        "    return dataframe\n",
        "\n",
        "df = remove_text_columns(df)"
      ],
      "metadata": {
        "id": "4c3p65MXrEGI"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.reset_index(drop=False, inplace=True)"
      ],
      "metadata": {
        "id": "ISOYD4PZuVo_"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Before dropping NAN\", df.shape)\n",
        "df = df.dropna()\n",
        "print(\"After dropping NAN\", df.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TF3Zgdo-vwar",
        "outputId": "78794530-c16d-416d-f521-5738c7eb7a5b"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before dropping NAN (8986, 127)\n",
            "After dropping NAN (8986, 127)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = df[\"label\"]\n",
        "X = df.drop(columns=['id', 'path', 'label', 'dataset', 'text', 'img', 'img_name'])"
      ],
      "metadata": {
        "id": "fI2Mor4WrEER"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Base Model"
      ],
      "metadata": {
        "id": "vWqZzIDGulLx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Enable GPU acceleration\n",
        "physical_devices = tf.config.list_physical_devices(\"GPU\")\n",
        "print(physical_devices)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R4_ZT1fbrD9h",
        "outputId": "fc4f45e3-1afc-4817-9624-338dd66222de"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
      ],
      "metadata": {
        "id": "hJfeytNnvTvh"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "61cHOz06vlmS",
        "outputId": "1fb2c108-abf9-431f-c6e2-86b9caf3477a"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8986, 120)"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Convert data to NumPy arrays\n",
        "X_train = np.array(X_train)\n",
        "X_test = np.array(X_test)\n",
        "y_train = np.array(y_train)\n",
        "y_test = np.array(y_test)"
      ],
      "metadata": {
        "id": "6f8QxXAuvQ-Q"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load your data and split into training and testing sets\n",
        "# Assuming you have X_train, y_train, X_test, and y_test\n",
        "\n",
        "# Create a sequential model\n",
        "model = keras.Sequential()\n",
        "\n",
        "# Add input layer\n",
        "model.add(layers.Input(shape=X_train.shape[1:]))\n",
        "\n",
        "# Add hidden layers with dropout\n",
        "model.add(layers.Dense(64, activation=\"relu\"))\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Dense(64, activation=\"relu\"))\n",
        "model.add(layers.Dropout(0.5))\n",
        "\n",
        "# Add output layer\n",
        "model.add(layers.Dense(1, activation=\"sigmoid\"))"
      ],
      "metadata": {
        "id": "nY85t09QrD7B"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "C6K6JJWJrD41"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model and obtain training accuracy\n",
        "history = model.fit(X_train, y_train, batch_size=32, epochs=10, validation_data=(X_test, y_test))\n",
        "training_accuracy = history.history['accuracy']\n",
        "\n",
        "# Evaluate the model on test data\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(\"Loss:\", loss)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Training Accuracy:\", training_accuracy[-1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p8wYwZ2grD2V",
        "outputId": "de6f7478-93ff-473c-d7da-e071aa6f8793"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "225/225 [==============================] - 2s 7ms/step - loss: 0.6524 - accuracy: 0.6341 - val_loss: 0.6558 - val_accuracy: 0.6352\n",
            "Epoch 2/10\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6526 - accuracy: 0.6343 - val_loss: 0.6573 - val_accuracy: 0.6352\n",
            "Epoch 3/10\n",
            "225/225 [==============================] - 1s 5ms/step - loss: 0.6523 - accuracy: 0.6345 - val_loss: 0.6580 - val_accuracy: 0.6352\n",
            "Epoch 4/10\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6523 - accuracy: 0.6337 - val_loss: 0.6585 - val_accuracy: 0.6352\n",
            "Epoch 5/10\n",
            "225/225 [==============================] - 1s 5ms/step - loss: 0.6522 - accuracy: 0.6351 - val_loss: 0.6563 - val_accuracy: 0.6352\n",
            "Epoch 6/10\n",
            "225/225 [==============================] - 1s 5ms/step - loss: 0.6504 - accuracy: 0.6344 - val_loss: 0.6558 - val_accuracy: 0.6352\n",
            "Epoch 7/10\n",
            "225/225 [==============================] - 1s 5ms/step - loss: 0.6521 - accuracy: 0.6349 - val_loss: 0.6573 - val_accuracy: 0.6346\n",
            "Epoch 8/10\n",
            "225/225 [==============================] - 1s 4ms/step - loss: 0.6483 - accuracy: 0.6347 - val_loss: 0.6581 - val_accuracy: 0.6346\n",
            "Epoch 9/10\n",
            "225/225 [==============================] - 1s 6ms/step - loss: 0.6501 - accuracy: 0.6337 - val_loss: 0.6587 - val_accuracy: 0.6352\n",
            "Epoch 10/10\n",
            "225/225 [==============================] - 2s 11ms/step - loss: 0.6475 - accuracy: 0.6352 - val_loss: 0.6587 - val_accuracy: 0.6357\n",
            "57/57 [==============================] - 0s 3ms/step - loss: 0.6587 - accuracy: 0.6357\n",
            "Loss: 0.6586652398109436\n",
            "Accuracy: 0.63570636510849\n",
            "Training Accuracy: 0.6352253556251526\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hyperparameter Tuning with 2 Layers and Gridsearch"
      ],
      "metadata": {
        "id": "qXijGMCdx7_m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras-tuner\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hoYSkN9AvsAk",
        "outputId": "012e7734-356c-477e-db28-7eba50172f6d"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting keras-tuner\n",
            "  Downloading keras_tuner-1.3.5-py3-none-any.whl (176 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.1/176.1 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (23.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (2.27.1)\n",
            "Collecting kt-legacy (from keras-tuner)\n",
            "  Downloading kt_legacy-1.0.5-py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (3.4)\n",
            "Installing collected packages: kt-legacy, keras-tuner\n",
            "Successfully installed keras-tuner-1.3.5 kt-legacy-1.0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import kerastuner as kt\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# Define the model architecture within a function\n",
        "def model_builder(hp):\n",
        "    model = keras.Sequential()\n",
        "    model.add(layers.Input(shape=X_train.shape[1:]))\n",
        "\n",
        "    # Tune the number of units in the first Dense layer\n",
        "    # Choose an optimal value between 32-512\n",
        "    hp_units1 = hp.Int('units1', min_value=32, max_value=512, step=32)\n",
        "    model.add(layers.Dense(units=hp_units1, activation='relu'))\n",
        "    model.add(layers.Dropout(0.5))\n",
        "\n",
        "    # Tune the number of units in the second Dense layer\n",
        "    hp_units2 = hp.Int('units2', min_value=32, max_value=512, step=32)\n",
        "    model.add(layers.Dense(units=hp_units2, activation='relu'))\n",
        "    model.add(layers.Dropout(0.5))\n",
        "\n",
        "    model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "    # Tune the learning rate for the optimizer \n",
        "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
        "\n",
        "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=hp_learning_rate),\n",
        "                  loss=keras.losses.BinaryCrossentropy(),\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "tuner = kt.Hyperband(model_builder,\n",
        "                     objective='val_accuracy',\n",
        "                     max_epochs=10,\n",
        "                     factor=3,\n",
        "                     directory='my_dir',\n",
        "                     project_name='intro_to_kt')\n",
        "\n",
        "# Start the tuning process\n",
        "tuner.search(X_train, y_train, epochs=10, validation_data=(X_test, y_test))\n",
        "\n",
        "# Get the optimal hyperparameters\n",
        "best_hps_1=tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "\n",
        "print(f\"\"\"\n",
        "The hyperparameter search is complete. The optimal number of units in the first densely-connected\n",
        "layer is {best_hps_1.get('units1')} and the optimal number of units in the second densely-connected layer is {best_hps_1.get('units2')}.\n",
        "The optimal learning rate for the optimizer is {best_hps_1.get('learning_rate')}.\n",
        "\"\"\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1hEwPUpsx_ms",
        "outputId": "8a0f5b7e-2130-41ca-f926-e5e71b774dc3"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 30 Complete [00h 00m 21s]\n",
            "val_accuracy: 0.63570636510849\n",
            "\n",
            "Best val_accuracy So Far: 0.63570636510849\n",
            "Total elapsed time: 00h 04m 08s\n",
            "\n",
            "The hyperparameter search is complete. The optimal number of units in the first densely-connected\n",
            "layer is 288 and the optimal number of units in the second densely-connected layer is 256.\n",
            "The optimal learning rate for the optimizer is 0.001.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hyperparameter Tuning with 2 Layers and RandomSearch"
      ],
      "metadata": {
        "id": "cCGoHIg2zRWK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import kerastuner as kt\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# Define the model architecture within a function\n",
        "def model_builder(hp):\n",
        "    model = keras.Sequential()\n",
        "    model.add(layers.Input(shape=X_train.shape[1:]))\n",
        "\n",
        "    # Tune the number of units in the first Dense layer\n",
        "    hp_units1 = hp.Int('units1', min_value=32, max_value=512, step=32)\n",
        "    model.add(layers.Dense(units=hp_units1, activation='relu'))\n",
        "    model.add(layers.Dropout(0.5))\n",
        "\n",
        "    hp_units2 = hp.Int('units2', min_value=32, max_value=512, step=32)\n",
        "    model.add(layers.Dense(units=hp_units2, activation='relu'))\n",
        "    model.add(layers.Dropout(0.5))\n",
        "\n",
        "    model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
        "\n",
        "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=hp_learning_rate),\n",
        "                  loss=keras.losses.BinaryCrossentropy(),\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "# Replace Hyperband with RandomSearch\n",
        "tuner = kt.RandomSearch(\n",
        "    model_builder,\n",
        "    objective='val_accuracy',\n",
        "    max_trials=50,  # Set to an appropriate value based on your resources\n",
        "    directory='my_dir',\n",
        "    project_name='intro_to_kt')\n",
        "\n",
        "tuner.search(X_train, y_train, epochs=10, validation_data=(X_test, y_test))\n",
        "\n",
        "# Get the optimal hyperparameters\n",
        "best_hps_2=tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "\n",
        "print(f\"\"\"\n",
        "The hyperparameter search is complete. The optimal number of units in the first densely-connected\n",
        "layer is {best_hps_2.get('units1')} and the optimal number of units in the second densely-connected layer is {best_hps_2.get('units2')}.\n",
        "The optimal learning rate for the optimizer is {best_hps_2.get('learning_rate')}.\n",
        "\"\"\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SIH_KR5ax_ko",
        "outputId": "468aeed8-168f-47be-8705-bfa268ac01ed"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 50 Complete [00h 00m 13s]\n",
            "val_accuracy: 0.6351501941680908\n",
            "\n",
            "Best val_accuracy So Far: 0.6362625360488892\n",
            "Total elapsed time: 00h 05m 31s\n",
            "\n",
            "The hyperparameter search is complete. The optimal number of units in the first densely-connected\n",
            "layer is 480 and the optimal number of units in the second densely-connected layer is 480.\n",
            "The optimal learning rate for the optimizer is 0.001.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Clearly the model is not capturing the patterns from our data. Therefore, we have to build a more deep network.**"
      ],
      "metadata": {
        "id": "onyAwrAy1Qhs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4 layers"
      ],
      "metadata": {
        "id": "lnRNK6z31uON"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import kerastuner as kt\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# Define the model architecture within a function\n",
        "def model_builder(hp):\n",
        "    model = keras.Sequential()\n",
        "    model.add(layers.Input(shape=X_train.shape[1:]))\n",
        "\n",
        "    # Tune the number of units in the first Dense layer\n",
        "    hp_units1 = hp.Int('units1', min_value=32, max_value=512, step=32)\n",
        "    model.add(layers.Dense(units=hp_units1, activation='relu'))\n",
        "    model.add(layers.Dropout(0.5))\n",
        "\n",
        "    hp_units2 = hp.Int('units2', min_value=32, max_value=512, step=32)\n",
        "    model.add(layers.Dense(units=hp_units2, activation='relu'))\n",
        "    model.add(layers.Dropout(0.5))\n",
        "\n",
        "    # Additional third Dense layer\n",
        "    hp_units3 = hp.Int('units3', min_value=32, max_value=512, step=32)\n",
        "    model.add(layers.Dense(units=hp_units3, activation='relu'))\n",
        "    model.add(layers.Dropout(0.5))\n",
        "\n",
        "    # Additional fourth Dense layer\n",
        "    hp_units4 = hp.Int('units4', min_value=32, max_value=512, step=32)\n",
        "    model.add(layers.Dense(units=hp_units4, activation='relu'))\n",
        "    model.add(layers.Dropout(0.5))\n",
        "\n",
        "    model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
        "\n",
        "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=hp_learning_rate),\n",
        "                  loss=keras.losses.BinaryCrossentropy(),\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "# Replace Hyperband with RandomSearch\n",
        "tuner = kt.RandomSearch(\n",
        "    model_builder,\n",
        "    objective='val_accuracy',\n",
        "    max_trials=50,  # Set to an appropriate value based on your resources\n",
        "    directory='my_dir',\n",
        "    project_name='kt_4layers')\n",
        "\n",
        "tuner.search(X_train, y_train, epochs=10, validation_data=(X_test, y_test))\n",
        "\n",
        "# Get the optimal hyperparameters\n",
        "best_hps_4=tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "\n",
        "print(f\"\"\"\n",
        "The hyperparameter search is complete. The optimal number of units in the first densely-connected\n",
        "layer is {best_hps_4.get('units1')}, in the second densely-connected layer is {best_hps_4.get('units2')},\n",
        "in the third densely-connected layer is {best_hps_4.get('units3')} and in the fourth densely-connected\n",
        "layer is {best_hps_4.get('units4')}.\n",
        "The optimal learning rate for the optimizer is {best_hps_4.get('learning_rate')}.\n",
        "\"\"\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5CqK_pESx_im",
        "outputId": "52a449df-42ea-46e7-81bd-491c2541a145"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 50 Complete [00h 00m 22s]\n",
            "val_accuracy: 0.6351501941680908\n",
            "\n",
            "Best val_accuracy So Far: 0.6351501941680908\n",
            "Total elapsed time: 00h 15m 23s\n",
            "\n",
            "The hyperparameter search is complete. The optimal number of units in the first densely-connected\n",
            "layer is 192, in the second densely-connected layer is 96,\n",
            "in the third densely-connected layer is 224 and in the fourth densely-connected\n",
            "layer is 128.\n",
            "The optimal learning rate for the optimizer is 0.01.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Vs627eAMx_gD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import kerastuner as kt\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.metrics import AUC\n",
        "\n",
        "# Define the model architecture within a function\n",
        "def model_builder(hp):\n",
        "    model = keras.Sequential()\n",
        "    model.add(layers.Input(shape=X_train.shape[1:]))\n",
        "\n",
        "    # Tune the number of units in the first Dense layer\n",
        "    hp_units1 = hp.Int('units1', min_value=32, max_value=512, step=32)\n",
        "    model.add(layers.Dense(units=hp_units1, activation='relu'))\n",
        "    model.add(layers.Dropout(0.5))\n",
        "\n",
        "    hp_units2 = hp.Int('units2', min_value=32, max_value=512, step=32)\n",
        "    model.add(layers.Dense(units=hp_units2, activation='relu'))\n",
        "    model.add(layers.Dropout(0.5))\n",
        "\n",
        "    # Additional third Dense layer\n",
        "    hp_units3 = hp.Int('units3', min_value=32, max_value=512, step=32)\n",
        "    model.add(layers.Dense(units=hp_units3, activation='relu'))\n",
        "    model.add(layers.Dropout(0.5))\n",
        "\n",
        "    # Additional fourth Dense layer\n",
        "    hp_units4 = hp.Int('units4', min_value=32, max_value=512, step=32)\n",
        "    model.add(layers.Dense(units=hp_units4, activation='relu'))\n",
        "    model.add(layers.Dropout(0.5))\n",
        "\n",
        "    # Additional fifth Dense layer\n",
        "    hp_units5 = hp.Int('units5', min_value=32, max_value=512, step=32)\n",
        "    model.add(layers.Dense(units=hp_units5, activation='relu'))\n",
        "    model.add(layers.Dropout(0.5))\n",
        "\n",
        "    # Additional sixth Dense layer\n",
        "    hp_units6 = hp.Int('units6', min_value=32, max_value=512, step=32)\n",
        "    model.add(layers.Dense(units=hp_units6, activation='relu'))\n",
        "    model.add(layers.Dropout(0.5))\n",
        "\n",
        "    model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
        "\n",
        "    def macro_f1(y_true, y_pred):\n",
        "        tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
        "        fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
        "        fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
        "\n",
        "        p = tp / (tp + fp + K.epsilon())\n",
        "        r = tp / (tp + fn + K.epsilon())\n",
        "\n",
        "        f1 = 2*p*r / (p+r+K.epsilon())\n",
        "        f1 = tf.where(tf.math.is_nan(f1), tf.zeros_like(f1), f1)\n",
        "        return K.mean(f1)\n",
        "\n",
        "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=hp_learning_rate),\n",
        "                  loss=keras.losses.BinaryCrossentropy(),\n",
        "                  metrics=['accuracy', macro_f1, AUC(name='auroc')])\n",
        "\n",
        "    return model\n",
        "\n",
        "# Replace Hyperband with RandomSearch\n",
        "tuner = kt.RandomSearch(\n",
        "    model_builder,\n",
        "    objective='val_accuracy',\n",
        "    max_trials=150,  # Set to an appropriate value based on your resources\n",
        "    directory='my_dir',\n",
        "    project_name='kt_6')\n",
        "\n",
        "tuner.search(X_train, y_train, epochs=10, validation_data=(X_test, y_test))\n",
        "\n",
        "# Get the optimal hyperparameters\n",
        "best_hps=tuner.get_best_hyperparameters\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 694
        },
        "id": "q467H2tqx-MH",
        "outputId": "429027f8-7f15-472a-f3c6-69197a1d5380"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 97 Complete [00h 00m 21s]\n",
            "val_accuracy: 0.6351501941680908\n",
            "\n",
            "Best val_accuracy So Far: 0.6351501941680908\n",
            "Total elapsed time: 00h 34m 52s\n",
            "\n",
            "Search: Running Trial #98\n",
            "\n",
            "Value             |Best Value So Far |Hyperparameter\n",
            "480               |128               |units1\n",
            "224               |480               |units2\n",
            "32                |128               |units3\n",
            "192               |256               |units4\n",
            "64                |256               |units5\n",
            "416               |224               |units6\n",
            "0.001             |0.001             |learning_rate\n",
            "\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-87-31aa939c8ff3>\u001b[0m in \u001b[0;36m<cell line: 71>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     69\u001b[0m     project_name='kt_6')\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m \u001b[0mtuner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;31m# Get the optimal hyperparameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras_tuner/engine/base_tuner.py\u001b[0m in \u001b[0;36msearch\u001b[0;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_trial_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_run_and_update_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_trial_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_search_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras_tuner/engine/base_tuner.py\u001b[0m in \u001b[0;36m_try_run_and_update_trial\u001b[0;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    268\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_try_run_and_update_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_and_update_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    271\u001b[0m             \u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrial_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOMPLETED\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras_tuner/engine/base_tuner.py\u001b[0m in \u001b[0;36m_run_and_update_trial\u001b[0;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_and_update_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    236\u001b[0m         if self.oracle.get_trial(trial.trial_id).metrics.exists(\n\u001b[1;32m    237\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moracle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras_tuner/engine/tuner.py\u001b[0m in \u001b[0;36mrun_trial\u001b[0;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[1;32m    285\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_checkpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m             \u001b[0mcopied_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"callbacks\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 287\u001b[0;31m             \u001b[0mobj_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_and_fit_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcopied_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m             \u001b[0mhistories\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras_tuner/engine/tuner.py\u001b[0m in \u001b[0;36m_build_and_fit_model\u001b[0;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[1;32m    212\u001b[0m         \u001b[0mhp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhyperparameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhypermodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m         tuner_utils.validate_trial_results(\n\u001b[1;32m    216\u001b[0m             \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moracle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"HyperModel.fit()\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras_tuner/engine/hypermodel.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, hp, model, *args, **kwargs)\u001b[0m\n\u001b[1;32m    142\u001b[0m             \u001b[0mIf\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0ma\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mit\u001b[0m \u001b[0mshould\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mthe\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m         \"\"\"\n\u001b[0;32m--> 144\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1683\u001b[0m                         ):\n\u001b[1;32m   1684\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1685\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1686\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1687\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 894\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    895\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    957\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m         \u001b[0;31m# no_variable_creation function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 959\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    960\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    961\u001b[0m       _, _, filtered_flat_args = (\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    141\u001b[0m       (concrete_function,\n\u001b[1;32m    142\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m--> 143\u001b[0;31m     return concrete_function._call_flat(\n\u001b[0m\u001b[1;32m    144\u001b[0m         filtered_flat_args, captured_inputs=concrete_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1755\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1756\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1757\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1758\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1759\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    379\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    382\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     53\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hkaSIJ9t62L3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}